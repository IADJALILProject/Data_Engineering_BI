# **Pipeline d'IngÃ©nierie de DonnÃ©es pour l'Analyse Bancaire**

Ce projet propose une solution complÃ¨te d'**ingÃ©nierie des donnÃ©es** pour le **secteur bancaire**, 
permettant l'analyse approfondie des domaines critiques comme les **transactions**, les **crÃ©dits**, les **fraudes**, et les **profils clients**. GrÃ¢ce Ã  une **architecture en Ã©toile**,
une **orchestration automatisÃ©e** avec **Prefect**, et un dÃ©ploiement via **Docker**, ce pipeline garantit robustesse, scalabilitÃ© et efficacitÃ©.

---

## **1. Objectifs du Projet**

Ce pipeline a Ã©tÃ© conÃ§u pour rÃ©pondre aux besoins dâ€™analyse des banques :

- **Ingestion** : Automatiser la collecte et le prÃ©traitement des donnÃ©es.
- **Transformation** : Structurer les donnÃ©es pour lâ€™analyse avec un **schÃ©ma en Ã©toile**.
- **Stockage** : Assurer un stockage fiable dans **PostgreSQL** et **Delta Lake**.
- **Monitoring** : ContrÃ´ler la qualitÃ© des donnÃ©es et alerter en cas dâ€™anomalie.
- **Orchestration** : Coordonner les tÃ¢ches du pipeline avec **Prefect**.
- **Planification** : Automatiser les exÃ©cutions Ã  intervalles rÃ©guliers via **Cron**.
- **DÃ©ploiement** : Conteneuriser lâ€™application avec **Docker** pour simplifier l'intÃ©gration.
- **Tests** : Valider la fiabilitÃ© des scripts grÃ¢ce Ã  des **tests unitaires**.

---

## **2. Architecture du Projet**

### **ModÃ¨le en Ã‰toile**

Le pipeline utilise un **modÃ¨le en Ã©toile** pour faciliter les requÃªtes analytiques complexes et amÃ©liorer la performance. Les donnÃ©es sont organisÃ©es comme suit :

- **Tables de Faits** :
   - `fact_transactions` : Historique des transactions bancaires.
   - `fact_loans` : DonnÃ©es relatives aux crÃ©dits octroyÃ©s.
   - `fact_payments` : Paiements associÃ©s aux crÃ©dits et transactions.
   - `fact_revenue` : Suivi des revenus financiers.
   - `fact_fraudes` : DÃ©tection et signalement des activitÃ©s frauduleuses.

- **Tables de Dimensions** :
   - `dim_clients` : Informations dÃ©taillÃ©es sur les clients.
   - `dim_products` : Liste des produits bancaires disponibles.
   - `dim_dates` : Structure temporelle pour lâ€™analyse des pÃ©riodes.
   - `dim_accounts` : DÃ©tails des comptes associÃ©s aux clients.
   - `dim_satisfaction` : Feedback des clients pour lâ€™amÃ©lioration des services.

---

## **3. Structure du Projet**

```bash
Data_Engineering_BI/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # DonnÃ©es brutes collectÃ©es
â”‚   â”œâ”€â”€ processed/                # DonnÃ©es nettoyÃ©es prÃªtes Ã  Ãªtre transformÃ©es
â”‚   â””â”€â”€ transformed/              # DonnÃ©es finales prÃªtes pour l'analyse
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py     # Importation et prÃ©traitement des donnÃ©es
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ transformation/
â”‚   â”‚   â”œâ”€â”€ cleaning.py           # Suppression des doublons et gestion des valeurs manquantes
â”‚   â”‚   â”œâ”€â”€ aggregation.py        # Calculs et mÃ©triques (totaux, moyennes)
â”‚   â”‚   â”œâ”€â”€ enrichment.py         # Jointures et enrichissement des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ star_schema.py        # Structuration du modÃ¨le en Ã©toile
â”‚   â”‚   â”œâ”€â”€ validation.py         # RÃ¨gles de validation pour garantir la cohÃ©rence
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ database_storage.py   # Stockage des donnÃ©es dans PostgreSQL
â”‚   â”‚   â”œâ”€â”€ delta_lake.py         # Sauvegarde incrÃ©mentale dans Delta Lake
â”‚   â”‚   â””â”€â”€ test_connexion.py     # VÃ©rification des connexions
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â”œâ”€â”€ data_quality.py       # Analyse de la qualitÃ© des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ alerts.py             # CrÃ©ation dâ€™alertes automatisÃ©es
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ orchestration/
â”‚       â”œâ”€â”€ orchestration.py      # DÃ©finition des flows avec Prefect
â”‚       â””â”€â”€ test_orchestration.py # Tests unitaires sur lâ€™orchestration
â”‚
â”œâ”€â”€ tests/                        # Tests unitaires pour chaque module
â”‚   â”œâ”€â”€ test_ingestion.py
â”‚   â”œâ”€â”€ test_transformation.py
â”‚   â””â”€â”€ test_storage.py
â”‚
â”œâ”€â”€ docker-compose.yml            # Configuration Docker
â”œâ”€â”€ deployment.yaml               # DÃ©ploiement des flows Prefect
â”œâ”€â”€ prefectignore                 # Exclusions spÃ©cifiques pour Prefect
â”œâ”€â”€ README.md                     # Documentation du projet
â””â”€â”€ requirements.txt              # Liste des dÃ©pendances Python
```

---

## **4. DÃ©tails des Ã‰tapes ClÃ©s**

### **1. Ingestion des DonnÃ©es**

**Script** : `data_ingestion.py`  
**Objectif** : Collecter les donnÃ©es brutes depuis **CSV**, **API**, ou autres sources.  
**Actions** :
- Chargement des donnÃ©es.
- Suppression des colonnes inutiles.
- Conversion des types pour standardiser les formats.

---

### **2. Transformation des DonnÃ©es**

**Scripts principaux** :
1. **`cleaning.py`** : 
   - Ã‰limination des doublons.
   - Remplacement des valeurs nulles.
2. **`aggregation.py`** : 
   - Calcul des mÃ©triques comme totaux, moyennes et agrÃ©gats.
3. **`enrichment.py`** : 
   - Fusion des diffÃ©rentes sources pour enrichir les donnÃ©es.
4. **`star_schema.py`** : 
   - CrÃ©ation du modÃ¨le en Ã©toile avec sÃ©paration des faits et dimensions.

---

### **3. Stockage**

**Scripts** :
- **`database_storage.py`** : Stockage final dans **PostgreSQL**.
- **`delta_lake.py`** : IntÃ©gration dans Delta Lake pour un stockage optimisÃ© et incrÃ©mental.

---

### **4. Monitoring et Alertes**

- **`data_quality.py`** : 
   - VÃ©rification des valeurs aberrantes.
   - ContrÃ´le de l'intÃ©gritÃ© des donnÃ©es.
- **`alerts.py`** : 
   - Envoi d'alertes via logs ou emails.

---

### **5. Orchestration avec Prefect**

**Script** : `orchestration.py`  
**FonctionnalitÃ©** : DÃ©finir et automatiser les tÃ¢ches sous forme de **flows** orchestrÃ©s par **Prefect**.  

Exemple de **Flow** Prefect :
```python
from prefect import Flow, task

@task
def load_data():
    print("Ingestion des donnÃ©es...")

@task
def transform_data():
    print("Transformation des donnÃ©es...")

with Flow("pipeline_data") as flow:
    load_data()
    transform_data()

flow.run()
```

---

### **6. DÃ©ploiement avec Docker**

**Fichier** : `docker-compose.yml`  
Conteneurisation de **PostgreSQL**, **Prefect** et des scripts pour un dÃ©ploiement simplifiÃ©.

---

### **7. Planification avec Cron**

Pour exÃ©cuter automatiquement les flows chaque jour Ã  8h00 :

```bash
0 8 * * * prefect deployment run "Full Data Pipeline Orchestration"
```

---

## **5. ExÃ©cution des Tests Unitaires**

Les tests assurent la fiabilitÃ© de chaque module du pipeline :

```bash
pytest tests/
```

---

## **6. Conclusion**

Ce pipeline offre une solution **robuste**, **automatisÃ©e**, et **scalable** pour l'analyse des donnÃ©es bancaires. GrÃ¢ce Ã  l'intÃ©gration de **Prefect**, **Docker**, et un modÃ¨le en Ã©toile optimisÃ©, il garantit des performances optimales pour des besoins analytiques complexes.

--- 
Voici la section **amÃ©liorÃ©e** pour l'interface web de **Prefect** Ã  intÃ©grer directement Ã  la fin de votre README.

---

## **7. Interface Web de Prefect**

L'interface web de **Prefect** permet de **visualiser**, **suivre** et **planifier** les diffÃ©rentes exÃ©cutions du pipeline. Voici les principaux Ã©lÃ©ments de l'interface :

### **8.1 Tableau de Bord**
- Le **Tableau de Bord** offre un aperÃ§u des exÃ©cutions rÃ©centes et en cours, ainsi que des statistiques globales.
- **Exemple** :
   - TÃ¢ches exÃ©cutÃ©es : **27 rÃ©ussites (75%)**, **9 Ã©checs (25%)**.
   - Visualisation graphique de l'historique des flux.

![Tableau de bord Prefect](55.PNG)

---

### **8.2 Gestion des Flux**
- La section **Flux** prÃ©sente tous les flux dÃ©finis dans le projet.
- Chaque flux affiche :
   - **Nom du Flux**
   - **DerniÃ¨re ExÃ©cution**
   - **Prochaine ExÃ©cution** planifiÃ©e
   - **Statut des dÃ©ploiements**

**Exemple** : Flux d'orchestration complet avec une prochaine course planifiÃ©e Ã  **08h00 tous les jours**.

![Gestion des Flux](22.PNG)

---

### **8.3 DÃ©ploiements**
- Permet de gÃ©rer et visualiser les dÃ©ploiements actifs.
- Un dÃ©ploiement **planifiÃ©** est exÃ©cutÃ© automatiquement Ã  des heures dÃ©finies via **Prefect Scheduler**.

**Exemple** : 
- **Horaires** : Planification quotidienne Ã  **08h00**.
- **Statut** : DÃ©ploiement "PrÃªt" en attente d'exÃ©cution.

![DÃ©ploiements Prefect](33.PNG)

---

### **8.4 Bassins de Travail (Work Pools)**
- Les **bassins de travail** assurent la gestion des workers pour exÃ©cuter les tÃ¢ches.
- **Statut** et **activitÃ©** des workers sont affichÃ©s en temps rÃ©el.

**Exemple** :
- Bassin : `default-agent-pool`
- Statut : **En ligne** (vert)
- Limite de simultanÃ©itÃ© : **illimitÃ©e**

![Bassins de Travail](44.PNG)

---

### **8.5 Monitoring des Courses**
- La section **Courses** permet de suivre l'Ã©tat d'exÃ©cution de chaque tÃ¢che avec des logs dÃ©taillÃ©s.
- Indicateurs clÃ©s :
   - **TÃ¢ches rÃ©ussies** (vert)
   - **TÃ¢ches Ã©chouÃ©es** (rouge)
   - **DurÃ©e dâ€™exÃ©cution**

![Monitoring des Courses](11.PNG)

---

### **8.6 Visualisation des ExÃ©cutions**
- Chaque exÃ©cution de flux est accompagnÃ©e dâ€™un suivi temporel sous forme de graphiques pour identifier les anomalies ou optimisations nÃ©cessaires.
- Les logs des tÃ¢ches permettent un **debugging** rapide.

---

### **8.7 Automatisation avec Prefect Scheduler**
- Prefect Scheduler est utilisÃ© pour **planifier les exÃ©cutions** des flux Ã  des intervalles dÃ©finis.
- Planification personnalisable :
   - **Quotidienne** : Tous les jours Ã  **08h00**.
   - **Cron Jobs** : PossibilitÃ© de dÃ©finir des rÃ¨gles complexes avec la syntaxe **cron**.

---

### **8.8 Points ClÃ©s de l'Interface**
- **ClartÃ© visuelle** pour chaque Ã©tape du pipeline.
- **Logs dÃ©taillÃ©s** pour diagnostiquer les erreurs.
- **Planification automatisÃ©e** pour un dÃ©ploiement fiable et rÃ©gulier.

---

Cette interface joue un rÃ´le central dans la **supervision** et lâ€™**orchestration** du pipeline, permettant un suivi optimal des **performances** et de la **qualitÃ© des donnÃ©es**.

---

### **9.Conclusion**
Ce projet d'ingÃ©nierie des donnÃ©es pour le secteur bancaire propose une solution complÃ¨te et automatisÃ©e pour le traitement des donnÃ©es critiques. En intÃ©grant des outils modernes tels que Prefect, Docker, Delta Lake, et des processus de transformation basÃ©s sur la modÃ©lisation en Ã©toile, il rÃ©pond aux besoins d'analyse approfondie dans divers domaines : transactions, prÃªts, fraudes et satisfaction client.

Forces du Projet :
Automatisation et Orchestration : GrÃ¢ce Ã  Prefect, le pipeline est exÃ©cutÃ© de maniÃ¨re fiable et planifiÃ©e avec un suivi dÃ©taillÃ© via l'interface web.
Robustesse : L'architecture modulaire permet une maintenance facile et une extension rapide des fonctionnalitÃ©s.
QualitÃ© des DonnÃ©es : Avec les contrÃ´les de qualitÃ© et les alertes automatisÃ©es, les risques d'erreurs sont minimisÃ©s.
ScalabilitÃ© : L'intÃ©gration de Delta Lake assure un stockage performant et Ã©volutif pour gÃ©rer de gros volumes de donnÃ©es.
Perspectives dâ€™AmÃ©lioration :
Optimisation des performances : Affiner les transformations pour rÃ©duire les temps de calcul sur de gros jeux de donnÃ©es.
Extensions : IntÃ©grer d'autres sources de donnÃ©es (e.g., APIs bancaires) pour enrichir les analyses.
Visualisation : Ajouter un tableau de bord BI pour une restitution interactive des rÃ©sultats analytiques.

Ce pipeline constitue ainsi une base solide pour accompagner les acteurs bancaires dans la prise de dÃ©cisions stratÃ©giques basÃ©es sur des donnÃ©es fiables et traitÃ©es en temps rÃ©el.


**PrÃªt Ã  Ãªtre dÃ©ployÃ© et utilisÃ© dans un environnement de production financier et bancaire !** ğŸš€
