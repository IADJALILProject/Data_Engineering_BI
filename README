# Pipeline d'Ing√©nierie de Donn√©es pour l'Analyse Bancaire

üöÄ **Description du Projet**

Ce projet propose une solution compl√®te d'**ing√©nierie des donn√©es** pour le **secteur bancaire**, permettant l'analyse approfondie des domaines critiques comme les **transactions**, les **cr√©dits**, les **fraudes** et les **profils clients**. Gr√¢ce √† une **architecture en √©toile**, une **orchestration automatis√©e** avec **Prefect**, et un d√©ploiement via **Docker**, ce pipeline garantit robustesse, scalabilit√© et efficacit√©.

---

## üéØ Objectifs du Projet

- **Ingestion** : Automatiser la collecte et le pr√©traitement des donn√©es.
- **Transformation** : Structurer les donn√©es pour l'analyse avec un **sch√©ma en √©toile**.
- **Stockage** : Assurer un stockage fiable dans **PostgreSQL** et **Delta Lake**.
- **Monitoring** : Contr√¥ler la qualit√© des donn√©es et alerter en cas d'anomalie.
- **Orchestration** : Coordonner les t√¢ches du pipeline avec **Prefect**.
- **Planification** : Automatiser les ex√©cutions √† intervalles r√©guliers via **Cron**.
- **D√©ploiement** : Conteneuriser l'application avec **Docker** pour simplifier l'int√©gration.
- **Tests** : Valider la fiabilit√© des scripts gr√¢ce √† des **tests unitaires**.

---

## üèó Architecture du Projet

### **Mod√®le en √âtoile**

Le pipeline utilise un **mod√®le en √©toile** pour faciliter les requ√™tes analytiques complexes et am√©liorer la performance.

| **Type**              | **Description**                                |
|-----------------------|-----------------------------------------------|
| **Faits**            | Transactions, cr√©dits, paiements, revenus, fraudes |
| **Dimensions**       | Clients, produits, dates, comptes, satisfaction |

---

## üìÇ Structure du Projet

```
Ing√©nierie_des_donn√©es_BI/
|
‚îú‚îÄ‚îÄ donnees/
‚îÇ   ‚îú‚îÄ‚îÄ raw/ # Donn√©es brutes collect√©es
‚îÇ   ‚îú‚îÄ‚îÄ processed/ # Donn√©es nettoy√©es pr√™tes √† √™tre transform√©es
‚îÇ   ‚îî‚îÄ‚îÄ transformed/ # Donn√©es finales pr√™tes pour l'analyse
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_ingestion.py # Importation et pr√©traitement des donn√©es
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ transformation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cleaning.py # Suppression des doublons et gestion des valeurs manquantes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aggregation.py # Calculs et m√©triques (totaux, moyennes)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ enrichment.py # Jointures et enrichissement des donn√©es
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ star_schema.py # Structuration du mod√®le en √©toile
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validation.py # R√®gles de validation pour garantir la coh√©rence
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ stockage/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database_storage.py # Stockage des donn√©es dans PostgreSQL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ delta_lake.py # Sauvegarde incr√©mentale dans Delta Lake
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_connexion.py # V√©rification des connexions
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ surveillance/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_quality.py # Analyse de la qualit√© des donn√©es
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alerts.py # Cr√©ation d'alertes automatis√©es
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ orchestration/
‚îÇ       ‚îú‚îÄ‚îÄ orchestration.py # D√©finition des flux avec Prefect
‚îÇ       ‚îî‚îÄ‚îÄ test_orchestration.py # Tests unitaires sur l'orchestration
‚îÇ
‚îú‚îÄ‚îÄ tests/ # Tests unitaires pour chaque module
‚îú‚îÄ‚îÄ docker-compose.yml # Configuration de Docker
‚îú‚îÄ‚îÄ deployment.yaml # D√©ploiement des flux Prefect
‚îú‚îÄ‚îÄ prefectignore # Exclusions sp√©cifiques pour Prefect
‚îú‚îÄ‚îÄ README.md # Documentation du projet
‚îî‚îÄ‚îÄ requirements.txt # Liste des d√©pendances Python
```

---

## üîë √âtapes Cl√©s

### 1. **Ingestion de Donn√©es**
**Script** : `data_ingestion.py`

- Collecte des donn√©es brutes depuis CSV, API, ou autres sources.
- Suppression des colonnes inutiles.
- Conversion des types pour standardiser les formats.

### 2. **Transformation des Donn√©es**
- Nettoyage des doublons et valeurs nulles (`cleaning.py`).
- Calcul des m√©triques comme les totaux et moyennes (`aggregation.py`).
- Fusion des sources pour enrichir les donn√©es (`enrichment.py`).
- Cr√©ation d'un mod√®le en √©toile (`star_schema.py`).

### 3. **Orchestration et D√©ploiement**
- Orchestration des t√¢ches avec **Prefect** (`orchestration.py`).
- Conteneurisation avec **Docker Compose** (`docker-compose.yml`).

---

## üß™ Tests et D√©ploiement

### **Tests Unitaires**
Ex√©cutez les tests pour valider la fiabilit√© de chaque module :
```bash
pytest tests/
```

### **D√©ploiement avec Docker**
Lancez l'application avec :
```bash
docker-compose up
```

---

## üåü Illustrations et Animations

1. **Diagramme de l'Architecture :**
```mermaid
graph TD
    A[Sources de Donn√©es] -->|Ingestion| B[Pipeline d'Ingestion]
    B -->|Transformation| C[Pipeline de Transformation]
    C -->|Stockage| D[Base de Donn√©es/PostgreSQL]
```

2. **GIF pour Flux Prefect :**
![Ex√©cution d'un Flux Prefect](https://example.com/flux-prefect.gif)



---

## üèÅ Conclusion

Ce pipeline constitue une solution robuste et scalable pour les besoins analytiques des banques. En int√©grant des outils modernes comme **Prefect** et **Docker**, il garantit un traitement fiable des donn√©es critiques avec une supervision optimale.

 et scalable pour les besoins analytiques des banques.

